{"meta":{"title":"SeoWon💕, SeoHun💕, EunA💕","subtitle":null,"description":null,"author":"고재성","url":"http://kjs850.github.io"},"pages":[],"posts":[{"title":"java memory 구조","slug":"java-memory-구조","date":"2018-12-13T10:23:07.769Z","updated":"2018-12-13T10:23:07.769Z","comments":true,"path":"2018/12/13/java-memory-구조/","link":"","permalink":"http://kjs850.github.io/2018/12/13/java-memory-구조/","excerpt":"","text":"date: 2018-12-13 16:15:25 메모리 구조 JVM은 OS로부터 받은 메모리를 나누어관리한다.이 메모리공간은… Runtime Data Area 라고 하는데 이를 5개 영역으로 쪼개서 관리한다. Method Area(=Class Area) Stack Area Heap Area Native Method Stack Area PC Register 크게는 메소드영역, 스택영역, 힙영역으로 나눈다. 메소드 영역클래스 파일의 바이트 코드가 로드되는 곳 스택 영역지역변수와 매개변수가 저장된다.쉽게 말해 프로그램의 실행과정에서 임시로 할당되고 그게 끝나면 소멸되는 것들이 저장된다.즉 메소드가 호출될때마다 그 메소드의 로컬 변수를 준비하고, 메소드 호출이 끝나면 그 메소드를 위해 준비했던 모든변수가 스택에서 제거 된다. 참조변수에 저장되는 메모리주소는 스택영역에 저장되지만, 그 주소가 가리키는 메모리는 모두 힙 영역에 저장된다. 힙 영역흔히 코드에서 new 명령을 통해 생성된 인스턴스 변수가 놓인다.힙 영역에 보관되는 메모리는 메소드 호출이 끝나도 사라지지 않고 유지된다.언제까지?가비지 컬렉터에 의해서 지워질때 까지.. 참고8가지 원시타입(primitive type).. byte, short, int, long, float, double, char, boolean..을 제외한 그외의 타입으로 정의된 변수들은 모조리 레퍼런스 변수, 즉 참조변수이다. Primitive와 Boxed Primitives 둘 중 무엇을 사용해야 할까?스택 영역에 저장되는 Primitive(기본자료형)과 힙영역에 저장되는 Boxed Primitives(객체형)간에는 메모리 효율과 접근속도면에서 Primitive Type이 뛰어나다. reference http://wanzargen.tistory.com/16?category=700063 http://wanzargen.tistory.com/17?category=700063 http://www.jpstory.net/2013/02/07/primitive-vs-boxed-primitives/ (자바 Primitive Type과 Boxed Primitives 둘 중 무엇을 사용할까?) tags:","categories":[],"tags":[]},{"title":"Java Garbage Collection","slug":"Java-Garbage-Collection","date":"2018-12-13T09:33:02.872Z","updated":"2018-12-13T09:33:02.872Z","comments":true,"path":"2018/12/13/Java-Garbage-Collection/","link":"","permalink":"http://kjs850.github.io/2018/12/13/Java-Garbage-Collection/","excerpt":"","text":"date: 2018-12-11 14:17:31 가비지 컬렉션 과정 - Generational Garbage Collection가비지 컬렉터는 두 가지 가설 하에 만들어졌다 대부분의 객체는 금방 접근 불가능 상태(unreachable)가 된다. 오래된 객체에서 젊은 객체로의 참조는 아주 적게 존재한다. 이러한 가설을 ‘weak generational hypothesis’라 한다. 이 가설의 장점을 최대한 살리기 위해서 HotSpot VM에서는 크게 2개로 물리적 공간을 나누었다.둘로 나눈 공간이 Young 영역과 Old 영역이다. Young 영역(Yong Generation 영역):새롭게 생성한 객체의 대부분이 여기에 위치한다.대부분의 객체가 금방 접근 불가능 상태가 되기 때문에 매우 많은 객체가 young 영역에생성되었다가 사라진다.이 영역에서 객체가 사라질때 Minor GC가 발생한다고 말한다. Old 영역(Old Generation 영역):접근 불가능 상태로 되지 않아 Young 영역에서 살아남은 객체가 여기로 복사된다.대부분 Young영역보다 크게 할당하며, 크기가 큰 만큼 Young 영역보다 GC는 적게 발생한다.이 영역에서 객체가 사라질 때 Major GC(혹은 Full GC)가 발생한다고 말한다. Permanent Generation 영역(이하 Perm 영역)Method Area(메소드 영역)라고도 한다.객체나 억류(intern)된 문자열 정보를 저장하는 곳이며, Old 영역에서 살아남은 객체가 영원히 남아 있는곳은 절대 아니다.이 영역에서 GC가 발생할수도 있는데, 여기서 GC가 발생해도 Major GC의 횟수에 포함된다. “Old 영역에 있는 객체가 Young 영역의 객체를 참조하는 경우가 있을 때에는 어떻게 처리될까?”카드 테이블이 존재하고 카드 테이블에는 Old영역에 있는 객체가 Young영역의 객체를 참조할 때마다 정보를 표시한다.Young영역의 GC를 실행할때는 Old영역에 있는 모든 객체의 참조를 확인하지 않고, 카드 테이블만 뒤져서 GC 대상인지 식별한다.카드 테이블은 write barrier를 사용하여 관리한다 Young 영역의 구성3개로 나뉨 Eden 영역 Survivor 영역 2개 아래와 같은 과정을 거친다. 새로 생성한 대부분의 객체는 Eden 영역에 위치한다. Eden 영역에서 GC가 한 번 발생한 후 살아남은 객체는 Survivor 영역 중 하나로 이동된다. Eden 영역에서 GC가 발생하면 이미 살아남은 객체가 존재하는 Survivor 영역으로 객체가 계속 쌓인다. 하나의 Survivor 영역이 가득 차게 되면 그 중에서 살아남은 객체를 다른 Survivor 영역으로 이동한다. 그리고 가득 찬 Survivor 영역은 아무 데이터도 없는 상태로 된다. 이 과정을 반복하다가 계속해서 살아남아 있는 객체는 Old 영역으로 이동하게 된다. HotSpot VM에서는 보다 빠른 메모리 할당을 위해서 두 가지 기술을 사용한다 bump-the-pointer TLABs(Thread-Local Allocation Buffers) Old 영역에 대한 GCGC 방식은 JDK 7을 기준으로 5가지 방식이 있다. Serial GC : 운영 서버에서 절대 사용하면 안 되는 방식이 Serial GC다. Serial GC는 데스크톱의 CPU 코어가 하나만 있을 때 사용하기 위해서 만든 방식이다. Serial GC를 사용하면 애플리케이션의 성능이 많이 떨어진다. Parallel GC Parallel Old GC(Parallel Compacting GC) Concurrent Mark &amp; Sweep GC(이하 CMS) G1(Garbage First) GC Serial GC (-XX:+UseSerialGC)Young 영역에서의 GC는 앞 절에서 설명한 방식을 사용한다.(Young 영역의 GC를 실행할 때에는 Old 영역에 있는 모든 객체의 참조를 확인하지 않고, 이 카드 테이블만 뒤져서 GC 대상인지 식별한다.)Old 영역의 GC는 mark-sweep-compact이라는 알고리즘을 사용한다.mark : Old 영역에 살아 있는 객체를 식별sweep : 힙(heap)의 앞 부분부터 확인하여 살아 있는 것만 남긴다compaction : 각 객체들이 연속되게 쌓이도록 힙의 가장 앞 부분부터 채워서 객체가 존재하는 부분과 객체가 없는 부분으로 나눈다 Parallel GC (-XX:+UseParallelGC)Serial GC와 기본적인 알고리즘은 같다.그러나 Serial GC는 GC를 처리하는 스레드가 하나인 것에 비해, Parallel GC는 GC를 처리하는 쓰레드가 여러 개이다.Parallel GC는 메모리가 충분하고 코어의 개수가 많을 때 유리하다.Throughput GC Parallel Old GC(-XX:+UseParallelOldGC)Parallel Old GC는 JDK 5 update 6부터 제공한 GC 방식Parallel GC와 비교하여 Old 영역의 GC 알고리즘만 다르다Mark-Summary-CompactionSummary : 앞서 GC를 수행한 영역에 대해서 별도로 살아 있는 객체를 식별한다. CMS GC (-XX:+UseConcMarkSweepGC)초기 Initial Mark 단계에서는 ….클래스 로더에서 가장 가까운 객체 중 살아 있는 객체만 찾는 것으로 끝낸다.따라서, 멈추는 시간은 매우 짧다.그리고 Concurrent Mark 단계에서는 방금 살아있다고 확인한 객체에서 참조하고 있는 객체들을 따라가면서 확인한다.이 단계의 특징은 다른 스레드가 실행 중인 상태에서 동시에 진행된다는 것이다.그 다음 Remark 단계에서는…. Concurrent Mark 단계에서 새로 추가되거나 참조가 끊긴 객체를 확인한다.마지막으로 Concurrent Sweep 단계에서는 쓰레기를 정리하는 작업을 실행한다.이 작업도 다른 스레드가 실행되고 있는 상황에서 진행한다. 이러한 단계로 진행되는 GC 방식이기 때문에 stop-the-world 시간이 매우 짧다.모든 애플리케이션의 응답 속도가 매우 중요할 때 CMS GC를 사용Low Latency GC라고도 부른다. 그런데 CMS GC는 stop-the-world 시간이 짧다는 장점에 반해 다음과 같은 단점이 존재한다. 다른 GC 방식보다 메모리와 CPU를 더 많이 사용한다.Compaction 단계가 기본적으로 제공되지 않는다.그리고 조각난 메모리가 많아 Compaction 작업을 실행하면 다른 GC 방식의 stop-the-world 시간보다 stop-the-world 시간이 더 길기 때문에Compaction 작업이 얼마나 자주, 오랫동안 수행되는지 확인해야 한다. G1 GC(-XX:+UseG1GC ) 다음 그림에서 보다시피, G1 GC는 바둑판의 각 영역에 객체를 할당하고 GC를 실행한다.그러다가, 해당 영역이 꽉 차면 다른 영역에서 객체를 할당하고 GC를 실행한다.즉, 지금까지 설명한 Young의 세가지 영역에서 데이터가 Old 영역으로 이동하는 단계가 사라진 GC 방식이라고 이해하면 된다.G1 GC는 장기적으로 말도 많고 탈도 많은 CMS GC를 대체하기 위해서 만들어 졌다. 힙 영역이 매우 큰 머신(최소 4GB)에서 돌리기에 적합한 GC.대신 CMS의 단점을 어느 정도는 극복해냈습니다.힙에 영역(Region) 이라는 개념을 도입한 것인데요, 힙을 여러 개의 Region으로 나눕니다.몇 몇 Region 은 Young Generation 영역으로 쓰이고, 나머지 몇 몇 Region 은 Old Generation 영역으로 쓰입니다.Young Generation 영역을 정리하는 건 Parallel이나 CMS처럼 멀티쓰레드로 정리를 합니다.(뭐 마찬가지로 지울건 지우고, 계속 쓰이고 있는건 Old Generation 영역으로 옮기겠죠.)그리고, Old Generation 영역에 해당하는 Region이 여러 개 있을 텐데 CMS처럼 백그라운드 쓰레드로 이 영역들을 정리를 합니다.그런데 CMS와 차이점은 중간 중간 쓸모없는 객체들을 쏙쏙 빼먹는게 아니라.한 Region을 통째로 정리해 버립니다.참조가 없는 객체들은 지우고, 사용 중인 객체는 다른 Region으로 고스란히 복사를 합니다.이 다른 Region으로 사용 중인 객체만 옮기는 과정에서 차곡차곡 옮기므로 Compacting이 되므로 메모리 파편화 현상이 생기지 않는 것이죠!그렇다면 CMS의 문제점이었던 CPU리소스를 많이 차지한다(1) 그리고 메모리파편화(2) 중에 메모리파편화를 해결한 GC가 되겠네요. 참고) -XX:+UseStringDeduplication : https://dzone.com/articles/easy-change-to-reduce-memory-by-20 referencehttps://d2.naver.com/helloworld/1329https://12bme.tistory.com/57https://okky.kr/article/379036http://wanzargen.tistory.com/17?category=700063 tags:","categories":[],"tags":[]},{"title":"process and thread","slug":"process-and-thread","date":"2018-12-05T02:09:13.313Z","updated":"2018-12-05T02:09:13.313Z","comments":true,"path":"2018/12/05/process-and-thread/","link":"","permalink":"http://kjs850.github.io/2018/12/05/process-and-thread/","excerpt":"","text":"date: 2018-12-05 11:03:07 ProcessA Process is a program in execution.It has its own address space, a call stack, and link to any resources such as open files.A computer system normally has multiple processes running at a time.The operating system keeps track of all these processes and facilitates their execution by sharing the processing time of the CPU among them. ThreadA thread is a path of execution within a process.Every process has at least one thread - called the main thread. The main thread can create additional threads within the process.Threads within a process share the process’s resources including memory and open files.However, every thread has its own call stack.Since threads share the same address space of the process, creating new threads and communicating between them is more efficient. referencehttps://www.callicoder.com/java-concurrency-multithreading-basics/#processes-and-threads categories: java tags: process thread","categories":[],"tags":[]},{"title":"git squash","slug":"git-squash","date":"2018-12-02T11:45:57.915Z","updated":"2018-12-02T11:45:57.915Z","comments":true,"path":"2018/12/02/git-squash/","link":"","permalink":"http://kjs850.github.io/2018/12/02/git-squash/","excerpt":"","text":"date: 2018-12-02 20:26:59 준비1234567891011121314151617181920212223242526272829 jake.ko  ~/Dev  cd git-study jake.ko  ~/Dev/git-study  ll jake.ko  ~/Dev/git-study  git initInitialized empty Git repository in /Users/jake.ko/Dev/git-study/.git/ jake.ko  ~/Dev/git-study   master  ll jake.ko  ~/Dev/git-study   master  ll -alrtotal 0drwxr-xr-x 10 jake.ko staff 320B 12 2 20:21 .gitdrwxr-xr-x 22 jake.ko staff 704B 12 2 20:16 ..drwxr-xr-x 3 jake.ko staff 96B 12 2 20:17 . jake.ko  ~/Dev/git-study   master  echo first &gt; first.txt jake.ko  ~/Dev/git-study   master  git add . jake.ko  ~/Dev/git-study   master ✚  git commit -m \"A\"[master (root-commit) 20611a0] A 1 file changed, 1 insertion(+) create mode 100644 first.txt jake.ko  ~/Dev/git-study   master  echo second &gt; second.txt jake.ko  ~/Dev/git-study   master  git add . jake.ko  ~/Dev/git-study   master ✚  git commit -m \"B\"[master 381d030] B 1 file changed, 1 insertion(+) create mode 100644 second.txt jake.ko  ~/Dev/git-study   master  echo third &gt; third.txt jake.ko  ~/Dev/git-study   master  git add . jake.ko  ~/Dev/git-study   master ✚  git commit -m \"C\"[master 52bfd68] C 1 file changed, 1 insertion(+) create mode 100644 third.txt jake.ko  ~/Dev/git-study   master  git log1234567891011121314151617commit 52bfd68372367dcbb2b4c1c5bb1ddb1086f02119 (HEAD -&gt; master)Author: jake.ko &lt;jake.ko@kakaocorp.com&gt;Date: Sun Dec 2 20:23:30 2018 +0900 Ccommit 381d030dafd61153bb3754c260b7216a9b5c47e9Author: jake.ko &lt;jake.ko@kakaocorp.com&gt;Date: Sun Dec 2 20:22:52 2018 +0900 Bcommit 20611a043cea164d8d3e5f5d73b3949974a5fe50Author: jake.ko &lt;jake.ko@kakaocorp.com&gt;Date: Sun Dec 2 20:22:19 2018 +0900 A git rebase -i HEAD~2123456789101112131415161718192021pick 381d030 Bpick 52bfd68 C# Rebase 20611a0..52bfd68 onto 20611a0 (2 commands)## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like \"squash\", but discard this commit's log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out 바꾸고 저장123pick 381d030 Bsquash 52bfd68 C 아래와 같은 수정이 가능 , 디폴트 그대로 저장 (.git/COMMIT_EDITMSG)12345678910111213141516171819202122232425# This is a combination of 2 commits.# This is the 1st commit message:B# This is the commit message #2:C# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date: Sun Dec 2 20:22:52 2018 +0900## interactive rebase in progress; onto 20611a0# Last commands done (2 commands done):# pick 381d030 B# squash 52bfd68 C# No commands remaining.# You are currently rebasing branch 'master' on '20611a0'.## Changes to be committed:# new file: second.txt# new file: third.txt# 결과1234567jake.ko  ~/Dev/git-study   master  git rebase -i HEAD~2[detached HEAD 6899e57] B Date: Sun Dec 2 20:22:52 2018 +0900 2 files changed, 2 insertions(+) create mode 100644 second.txt create mode 100644 third.txtSuccessfully rebased and updated refs/heads/master git log123456789101112131415'git help -a' and 'git help -g' list available subcommands and somecommit 6899e57839eb085a8f0188572aec93ab1b8db74b (HEAD -&gt; master)Author: jake.ko &lt;jake.ko@kakaocorp.com&gt;Date: Sun Dec 2 20:22:52 2018 +0900 B Ccommit 20611a043cea164d8d3e5f5d73b3949974a5fe50Author: jake.ko &lt;jake.ko@kakaocorp.com&gt;Date: Sun Dec 2 20:22:19 2018 +0900 A(END) tags: [git]","categories":[],"tags":[]},{"title":"Kafka Consumer offset reset - java code","slug":"Kafka-Consumer-offset-reset-java-code","date":"2018-11-28T09:21:53.081Z","updated":"2018-11-28T09:21:53.081Z","comments":true,"path":"2018/11/28/Kafka-Consumer-offset-reset-java-code/","link":"","permalink":"http://kjs850.github.io/2018/11/28/Kafka-Consumer-offset-reset-java-code/","excerpt":"","text":"date: 2018-11-28 18:09:53 java로 특정 시간의 offset 부터 가져오기123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.example.kafkaoffsettest;import org.apache.kafka.clients.consumer.ConsumerRecord;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;import org.apache.kafka.clients.consumer.OffsetAndTimestamp;import org.apache.kafka.common.TopicPartition;import org.joda.time.DateTime;import java.time.Instant;import java.util.*;import static com.example.kafkaoffsettest.KafkaConsumerUtil.TOPIC;import static com.example.kafkaoffsettest.KafkaConsumerUtil.createConsumer;import static java.time.temporal.ChronoUnit.DAYS;import static java.time.temporal.ChronoUnit.MINUTES;public class KafkaConsumerFromTime &#123; public static void main(String[] args) &#123; KafkaConsumer&lt;String, String&gt; consumer = createConsumer(); consumer.subscribe(Arrays.asList(TOPIC)); boolean flag = true; while (true) &#123; ConsumerRecords&lt;String, String&gt; records = consumer.poll(100); if (flag) &#123; Set&lt;TopicPartition&gt; assignments = consumer.assignment(); Map&lt;TopicPartition, Long&gt; query = new HashMap&lt;&gt;(); for (TopicPartition topicPartition : assignments) &#123; query.put( topicPartition, Instant.now().minus(1, DAYS).toEpochMilli()); &#125; Map&lt;TopicPartition, OffsetAndTimestamp&gt; result = consumer.offsetsForTimes(query); result.entrySet() .stream() .forEach(entry -&gt; consumer.seek( entry.getKey(), Optional.ofNullable(entry.getValue()) .map(OffsetAndTimestamp::offset) .orElse(new Long(0)))); flag = false; &#125; for (ConsumerRecord&lt;String, String&gt; record : records) &#123; long timestamp = record.timestamp(); DateTime dateTime = new DateTime(timestamp); System.out.printf(\"dateTime = %s, offset = %d, key = %s, value = %s%n\", dateTime, record.offset(), record.key(), record.value()); &#125; &#125; &#125;&#125; 결과1234567&gt; date Wed Nov 28 18:20:25 KST 2018//실행결과dateTime = 2018-11-28T17:43:58.201+09:00, offset = 26, key = null, value = foo1dateTime = 2018-11-28T17:43:58.208+09:00, offset = 27, key = null, value = foo2dateTime = 2018-11-28T17:43:58.208+09:00, offset = 28, key = null, value = foo3 tags: [kafka, offset, java]","categories":[],"tags":[]},{"title":"Kafka Consumer offset reset 하기","slug":"Kafka-Consumer-offset-reset-하기","date":"2018-11-25T14:56:30.189Z","updated":"2018-11-25T14:56:30.190Z","comments":true,"path":"2018/11/25/Kafka-Consumer-offset-reset-하기/","link":"","permalink":"http://kjs850.github.io/2018/11/25/Kafka-Consumer-offset-reset-하기/","excerpt":"","text":"date: 2018-11-22 16:25:22 그룹 지정하여 토픽 수신123456789101112 ✘ jake.ko@jakekoui-MacBook-Pro  ~  kafka-console-consumer --bootstrap-server localhost:9092 --topic test --group testGroup --from-beginningaaabbbccc``` ## 컨슈머 그룹별 offset 상태 확인```bash✘ jake.ko@jakekoui-MacBook-Pro  ~  kafka-consumer-groups --bootstrap-server localhost:9092 --group testGroup --describeTOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-IDtest 0 3 3 0 consumer-1-39ea110a-7f65-4ec3-8a9d-22c82d8be469 /172.26.113.148 consumer-1 TOPIC: 토픽 이름 PARTITION: consumer group 내의 각 consumer가 할당된 파티션 번호 CURRENT-OFFSET: 현재 consumer group의 consumer가 각 파티션에서 마지막으로 offset을 commit한 값 LOG-END-OFFSET: producer쪽에서 마지막으로 생성한 레코드의 offset LAG: LOG-END-OFFSET에서 CURRENT-OFFSET를 뺀 값. 컨슈머 그룹의 offset reset1kafka-consumer-groups --bootstrap-server localhost:9092 --group testGroup --topic test --reset-offsets --to-earliest --execute –topic 대신 –all-topics를 지정하면 모든 토픽에 대해서 실행이 가능하다. –execute 옵션을 제거하고, –dry-run옵션으로 실행하면 실제 반영되지 않고 어떻게 변할지 결과만 출력하는 dry run이 가능하다. 1234 jake.ko@jakekoui-MacBook-Pro  ~  kafka-consumer-groups --bootstrap-server localhost:9092 --group testGroup --topic test --reset-offsets --to-earliest --dry-runTOPIC PARTITION NEW-OFFSETtest 0 0 주의사항: 해당 그룹의 컨슈머를 멈추고 리셋해야 한다.(consumer group이 실행중인 상태에 offset reset을 진행하는 경우 reset은 실패한다.) 12345 jake.ko@jakekoui-MacBook-Pro  ~  kafka-consumer-groups --bootstrap-server localhost:9092 --group testGroup --topic test --reset-offsets --to-earliest --dry-runError: Assignments can only be reset if the group 'testGroup' is inactive, but the current state is Stable.TOPIC PARTITION NEW-OFFSET jake.ko@jakekoui-MacBook-Pro  ~  샘플기존의 프로듀서가 지속적으로 메시지 생산1234567jake.ko@jakekoui-MacBook-Pro  ~  kafka-console-producer --broker-list localhost:9092 --topic test&gt;aaa&gt;bbb&gt;ccc&gt;ddd&gt;eee&gt; 중간부터 컨슘123✘ jake.ko@jakekoui-MacBook-Pro  ~  kafka-console-consumer --bootstrap-server localhost:9092 --topic test --group testGroupdddeee 리셋 후 처음부터 컨슘하도록 변경12345jake.ko@jakekoui-MacBook-Pro  ~  kafka-consumer-groups --bootstrap-server localhost:9092 --group testGroup --topic test --reset-offsets --to-earliest --executeTOPIC PARTITION NEW-OFFSETtest 0 0 jake.ko@jakekoui-MacBook-Pro  ~  컨슘 재개 후 결과 (offset 리셋되어, 처음부터 컨슘한다.)123456 ✘ jake.ko@jakekoui-MacBook-Pro  ~  kafka-console-consumer --bootstrap-server localhost:9092 --topic test --group testGroupaaabbbcccdddeee 오프셋의 위치를 재설정하기 위한 아래와같은 상세 옵션들이 있다. –shift-by &lt;Long: number-of-offsets&gt; 형식 (+/- 모두 가능) –to-offset &lt;Long: offset&gt; –to-current –by-duration &lt;String: duration&gt; : 형식 ‘PnDTnHnMnS’ –to-datetime &lt;String: datetime&gt; : 형식 ‘YYYY-MM-DDTHH:mm:SS.sss’ –to-latest –to-earliest –to-datetime의 경우 kafka에서 데이터를 읽어서 다른곳에 저장하는 중에 데이터 유실 또는 중복 write 등이 발생한 경우에 날짜 단위로 데이터를 다시 불러와서 재처리하고 싶은 경우 매우 유용하다. CLI가 아닌 Java 코드로 offset reset하기Kafka의 경우 사용 형태에 따라 Consumer API와 Stream API 두가지를 제공한다. Consumer API 개별 이벤트 단위의 low level 처리가 필요한 경우 datetime, offset 을 지정해서 원하는 대로 reset 가능 Stream API Stream processing이 필요한 경우 offset reset 기능 없음 (위에서 언급한 CLI tool을 사용해야함) Consumer API를 사용할때 Java코드 레벨에서 programmatical하게 offset을 리셋하는 방법은 다음과 같다.먼저 KafkaConsumer가 생성한 후에1KafkaConsumer&lt;Object, Object&gt; consumer = new KafkaConsumer&lt;&gt;(properties, keyDeser, valueDeser); consumer loop에 진입하여 consumer.poll()을 부르기 전에, 생성된 consumer 객체에 대해 offset을 변경하는 다음 함수들을 호출하여 offset을 원하는 대로 설정할 수 있다. seekToBeginning: earliest로 reset seekToEnd: latest로 reset seek : 지정 offset으로 reset offsetsForTimes: datetime 기준으로 reset reference https://www.letmecompile.com/kafka-consumer-offset-reset/ https://gist.github.com/marwei/cd40657c481f94ebe273ecc16601674b http://blog.sysco.no/integration/kafka-rewind-consumers-offset/ tags: kafka, offset","categories":[],"tags":[]},{"title":"kafka 설치 및 구동","slug":"kafka-설치-및-구동","date":"2018-11-22T07:28:12.775Z","updated":"2018-11-22T07:28:12.775Z","comments":true,"path":"2018/11/22/kafka-설치-및-구동/","link":"","permalink":"http://kjs850.github.io/2018/11/22/kafka-설치-및-구동/","excerpt":"","text":"date: 2018-11-22 14:35:57 설치1234567891011121314151617181920&gt; brew install kafka..... 생략... brew services start kafkaOr, if you don't want/need a background service you can just run: zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties &amp; kafka-server-start /usr/local/etc/kafka/server.properties==&gt; Summary🍺 /usr/local/Cellar/kafka/2.0.0: 160 files, 46.8MB==&gt; Caveats==&gt; zookeeperTo have launchd start zookeeper now and restart at login: brew services start zookeeperOr, if you don't want/need a background service you can just run: zkServer start==&gt; kafkaTo have launchd start kafka now and restart at login: brew services start kafkaOr, if you don't want/need a background service you can just run: zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties &amp; kafka-server-start /usr/local/etc/kafka/server.properties 주키퍼 구동 12345678jake.ko@jakekoui-MacBook-Pro  ~  zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties[2018-11-22 14:39:11,550] INFO Reading configuration from: /usr/local/etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)[2018-11-22 14:39:11,553] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)[2018-11-22 14:39:11,553] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)[2018-11-22 14:39:11,555] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)[2018-11-22 14:39:11,555] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)[2018-11-22 14:39:11,571] INFO Reading configuration from: /usr/local/etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)생략... 카프카 구동 1234567891011jake.ko@jakekoui-MacBook-Pro  ~  kafka-server-start /usr/local/etc/kafka/server.properties[2018-11-22 14:39:25,676] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)[2018-11-22 14:39:26,191] INFO starting (kafka.server.KafkaServer)[2018-11-22 14:39:26,192] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)[2018-11-22 14:39:26,208] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)[2018-11-22 14:39:26,215] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)[2018-11-22 14:39:26,215] INFO Client environment:host.name=172.26.113.148 (org.apache.zookeeper.ZooKeeper)[2018-11-22 14:39:26,215] INFO Client environment:java.version=1.8.0_161 (org.apache.zookeeper.ZooKeeper)[2018-11-22 14:39:26,215] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)[2018-11-22 14:39:26,215] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_161.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)생략... 토픽 생성12jake.ko@jakekoui-MacBook-Pro  ~  kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testCreated topic \"test\". 토픽 보내기(produce)12345 jake.ko@jakekoui-MacBook-Pro  ~  kafka-console-producer --broker-list localhost:9092 --topic test&gt;aaa&gt;bbb&gt;ccc&gt; 토픽 수신(consume)1234 jake.ko@jakekoui-MacBook-Pro  ~  kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginningaaabbbccc reference https://medium.com/@Ankitthakur/apache-kafka-installation-on-mac-using-homebrew-a367cdefd273 tags: kafka, mac, install","categories":[],"tags":[]},{"title":"kafka streams는 무엇인가?","slug":"kafka-streams는-무엇인가","date":"2018-11-22T04:19:54.220Z","updated":"2018-11-22T04:19:54.220Z","comments":true,"path":"2018/11/22/kafka-streams는-무엇인가/","link":"","permalink":"http://kjs850.github.io/2018/11/22/kafka-streams는-무엇인가/","excerpt":"","text":"date: 2018-11-22 10:48:50 소개 카프카 스트림즈는 카프카에 저장된 데이터를 처리하고 분석하기 위해 개발된 클라이언트 라이브러리다. 카프카 스트림즈는 이벤트 처리 시간과 처리 시간을 분리해서 다루고 다양한 시간 간격 옵션을 지원하기에 실시간 분석을 간단하면서도 효율적으로 진행할 수 있다. 특징 간단하고 가벼운 클라이언트 라이브러리이기 때문에 기존 애플리케이션이나 자바 애플리케이션에서 쉽게 사용할수 있습니다. 시스템이나 카프카에 대한 의존성이 없습니다. 이중화된 로컬 상태 저장소를 지원합니다. 카프카 브로커나 클라이언트에 장애가 생기더라도 스트림에 대해서 1번만 처리가 되도록 보장합니다. 밀리초 단위의 처리 지연을 보장하기 위해 한번에 한 레코드만 처리합니다. 간단하게 스트림 처리 프로그램을 만들 수 있도록 고수준의 스트림 DSL(Domain Specific Language)을 지원하고, 저수준의 프로세싱 API도 제공합니다. 스트림 만들기 예제1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package test.kafka; import org.apache.kafka.common.serialization.Serdes;import org.apache.kafka.streams.KafkaStreams;import org.apache.kafka.streams.StreamsBuilder;import org.apache.kafka.streams.StreamsConfig;import org.apache.kafka.streams.Topology; import java.util.Properties;import java.util.concurrent.CountDownLatch; public class Pipe &#123; public static void main(String[] args) throws Exception &#123; Properties props = new Properties(); props.put(StreamsConfig.APPLICATION_ID_CONFIG, \"jake-streams-pipe\"); props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\"); props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass()); props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass()); final StreamsBuilder builder = new StreamsBuilder(); builder.stream(\"jake-stream-in\").to(\"jake-stream-out\"); final Topology topology = builder.build(); System.out.println(topology.describe()); final KafkaStreams streams = new KafkaStreams(topology, props); final CountDownLatch latch = new CountDownLatch(1); // attach shutdown handler to catch control-c Runtime.getRuntime().addShutdownHook(new Thread(\"streams-shutdown-hook\") &#123; @Override public void run() &#123; streams.close(); latch.countDown(); &#125; &#125;); try &#123; streams.start(); latch.await(); &#125; catch (Throwable e) &#123; System.exit(1); &#125; System.exit(0); &#125; &#125; 출력 결과아래와 같은 토폴로지가 만들어진다. 하나의 토픽을 그대로 복사한 토픽이 생겼다. ( jake-stream-in 의 토픽내의 메시지를 실시간으로 복사하는 jake-stream-out 토픽이 생겼다) 응용jake-stream-out이란 토픽에 실시간으로 분석한 결과를 넣을 수 있다. (ex. 단어 split , 또는 단어 빈도 세기) 참고 카프카 console-producer console-consumer는 그냥 콘솔로 메시지 생성, 소비한다. 카프카 설치 파일의 bin에 위치해 있음. (http://kafka.apache.org/downloads.html)","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2018-11-21T08:01:00.716Z","updated":"2018-11-21T08:01:00.716Z","comments":true,"path":"2018/11/21/hello-world/","link":"","permalink":"http://kjs850.github.io/2018/11/21/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Starthttps://hyunseob.github.io/2016/02/23/start-hexo/ Create a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}